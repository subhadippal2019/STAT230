\documentclass[compress]{beamer}
\mode<presentation>
\setbeamercovered{transparent}
\usetheme{Warsaw}
%\useoutertheme{smoothtree}
\usepackage{multirow}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{xmpmulti}
\usepackage{multicol}
\usepackage{colortbl}

%\setbeamersize{text margin left=.25 in,text margin right=.25 in}
\setbeamersize{text margin left=.15 in,text margin right=.15 in}
\usepackage[authoryear]{natbib}


\usepackage{epstopdf}
\usepackage{xcolor}
\usepackage{latexcolors}
%\usepackage[dvipsnames]{xcolor}
\definecolor{antiquebrass}{rgb}{0.8, 0.58, 0.46}
\definecolor{babyblueeyes}{rgb}{0.63, 0.79, 0.95}
\definecolor{babyblue}{rgb}{0.54, 0.81, 0.94}
\definecolor{bistre}{rgb}{0.24, 0.17, 0.12}
\definecolor{brightlavender}{rgb}{0.75, 0.58, 0.89}
\definecolor{bulgarianrose}{rgb}{0.28, 0.02, 0.03}
\definecolor{slateblue}{rgb}{0.56, 0.74, 0.56}
\definecolor{cordovan}{rgb}{0.54, 0.25, 0.27}
\definecolor{darkbyzantium}{rgb}{0.36, 0.22, 0.33}

\setbeamercolor{structure}{fg=bittersweet!70, bg= black!60}







\usepackage{tikz}
\usetikzlibrary{shadows,calc}
\usetikzlibrary{shadows.blur}
\usetikzlibrary{shapes.symbols}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{multirow}
%%%%%%%%% shaddow image %%%%%
% some parameters for customization
\def\shadowshift{3pt,-3pt}
\def\shadowradius{6pt}
\colorlet{innercolor}{black!60}
\colorlet{outercolor}{gray!05}
% this draws a shadow under a rectangle node
\newcommand\drawshadow[1]{
\begin{pgfonlayer}{shadow}
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.south west)+(\shadowshift)+(\shadowradius/2,\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) circle (\shadowradius);
    \shade[outercolor,inner color=innercolor,outer color=outercolor] ($(#1.north east)+(\shadowshift)+(-\shadowradius/2,-\shadowradius/2)$) circle (\shadowradius);
    \shade[top color=innercolor,bottom color=outercolor] ($(#1.south west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) rectangle ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$);
    \shade[left color=innercolor,right color=outercolor] ($(#1.south east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$);
    \shade[bottom color=innercolor,top color=outercolor] ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$);
    \shade[outercolor,right color=innercolor,left color=outercolor] ($(#1.south west)+(\shadowshift)+(-\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north west)+(\shadowshift)+(\shadowradius/2,-\shadowradius/2)$);
    \shade[outercolor,right color=innercolor,left color=innercolor] ($(#1.north west)+(-\shadowradius/12,\shadowradius/12)$) rectangle ($(#1.south east)+(\shadowradius/12,-\shadowradius/12)$);%Frame
    \filldraw ($(#1.south west)+(\shadowshift)+(\shadowradius/2,\shadowradius/2)$) rectangle ($(#1.north east)+(\shadowshift)-(\shadowradius/2,\shadowradius/2)$);
\end{pgfonlayer}
}
% create a shadow layer, so that we don't need to worry about overdrawing other things
\pgfdeclarelayer{shadow} 
\pgfsetlayers{shadow,main}
% Define image shadow command
\newcommand\shadowimage[2][]{%
\begin{tikzpicture}
\node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[#1]{#2}};
\drawshadow{image}
\end{tikzpicture}}
\usepackage{calligra}

\DeclareMathOperator*{\argmax}{Arg\,max}
\DeclareMathOperator*{\argmin}{Arg\,min}
\newcommand{\norm}[1]{\left\Vert #1 \right\Vert }
\newcommand{\bbetaHat}{ \widehat{\bbeta}}
\newcommand{\bbetaLSE}{ \widehat{\bbeta}_{_{\text{LSE}}}}
\newcommand{\bbetaMLE}{ \widehat{\bbeta}_{_{\text{MLE}}}}
\newcommand{\sqBullet}[1]{  {\tiny \tiny \tiny \qBoxCol{#1!60}{ }} }
%***************
%\newtheorem{thm}{Theorem}
\input{../LatexSupportFiles/definition_include}
\input{../LatexSupportFiles/BoxDef}
\input{../LatexSupportFiles/MatrixDef}











\title{  STAT 320: Principles of Probability\\ {\color{black}    \HLTW{\text{Unit 5} (\HLTY{\text{PART:B}})}\\ 
\qBrd[3in]{rose!30}{A Few Discrete Random Variables}}}

\author[UAEU]
{United Arab Emirates University}
\institute[UAEU] % (optional, but mostly needed)
{
  \inst{Department of Statistics}%
  %Indian Institute of Management,  Udaipur\\
  \vspace{0.1in}

  
}

\date{}


\newcommand{\Xnew}{ \HLTEQ[orange]{X_{_{\text{i}}}} }
\newcommand{\Ynew}{ \HLTEQ[orange]{Y_{_{\text{i}}}} }

%\date{\today}

\AtBeginSection[]
{
  \begin{frame}{Inhalt}
 % \begin{multicols}{1}
	\frametitle{Outline}
    \tableofcontents[currentsection]
  %  \end{multicols}
  \end{frame}
}

\begin{document}
\maketitle

%\begin{frame}{Outline}
%%\begin{multicols}{}
%  \tableofcontents
%%\end{multicols}
%\end{frame}

%\section{Introduction to DSBA 2023}
%
%
%\begin{frame}
%\qBoxCol{blue!30}{
%\begin{center} Course  Website \end{center}
%\qbx[4.2in]{teal!40}{\sqBullet{teal} \color{blue} $ \href{https://sites.google.com/iimu.ac.in/dsba2023e/home}{https://sites.google.com/iimu.ac.in/dsba2023e/home}$
%}\\
%\qbx[3.0in]{green!40}{ \sqBullet{green} Regular Announcements.
%}\\
%\qbx[3.0in]{olive!40}{\sqBullet{olive}  Slides and other materials.
%}
%}
%
%\pause
%\qBoxCol{blue!30}{
%\sqBullet{blue}
%You can contact the instructor at {\it subhadip.pal@iimu.ac.in} and schedule for office hours.  
%}
%\pause
%\qBoxCol{olive!30}{
%\sqBullet{olive}
%Mr. Praveen Kumar has been assigned as Teaching Assistant (TA) for this course.  His email I'd is:  {\it praveen.kumar@iimu.ac. }
%}
%
%
%\end{frame}
%


%
%\begin{frame}{Course Outline}
%\hspace{-.1in}\qBoxCol{blue!35}{
%% Please add the following required packages to your document preamble:
%% \usepackage{booktabs}
%\begin{table}[]
%\begin{tabular}{@{}lll@{}}
%\toprule
%         & Topics                                                & Dataset or Case                                    \\ \midrule \midrule
%\rowcolor{blue!20}     \multicolumn{1}{|l|}{1-2}   & \multicolumn{1}{l|}{Overview of Data Science}        & \multicolumn{1}{l|}{Household Data}                \\ \midrule
%\rowcolor{purple!20} 
%\multicolumn{1}{|l|}{3-5}   & \multicolumn{1}{l|}{Data Visualization}              & \multicolumn{1}{l|}{Global Super Store }       \\ \midrule
%\rowcolor{blue!20} 
%\multicolumn{1}{|l|}{6}     & \multicolumn{1}{l|}{Introduction to R/ JMP}          & \multicolumn{1}{l|}{}                              \\ \midrule
%\rowcolor{purple!20} 
%\multicolumn{1}{|l|}{7}     & \multicolumn{1}{l|}{Regression Analysis}             & \multicolumn{1}{l|}{Display \& Liquor Sales} \\ \midrule
%\rowcolor{blue!20} 
%\multicolumn{1}{|l|}{8}     & \multicolumn{1}{l|}{Multiple Regression}             & \multicolumn{1}{l|}{}                              \\ \midrule
%\rowcolor{purple!20} 
%\multicolumn{1}{|l|}{9}     & \multicolumn{1}{l|}{Dealing with Nominal Covariates} & \multicolumn{1}{l|}{Gender Divide}                 \\ \midrule
%\rowcolor{blue!20} 
%\multicolumn{1}{|l|}{10}    & \multicolumn{1}{l|}{Regression Diagonistics}         & \multicolumn{1}{l|}{}                              \\ \midrule
%\rowcolor{purple!20} 
%\multicolumn{1}{|l|}{11-12} & \multicolumn{1}{l|}{Project Presentations}            &\multicolumn{1}{l|}{}          \\\midrule \bottomrule
%\end{tabular}
%\end{table}
%}
%\end{frame}


%\begin{frame}{Case Study }
%\qBoxCol{teal!40}{\vspace{1in}\begin{center}\sqBullet{teal} \Large Case: Liquor sales and display space \end{center}
%\vspace{1in}
%}\\
%\end{frame}










\section{Binomial Distribution  }






\begin{frame}
\begin{itemize}
\qBrd[4.2in]{amber(sae/ece)!40}{
\item[\sqBullet{amber(sae/ece)}] A quality controlling team in TV manufacturer evaluates a products before they are send to market. They are interested in idensifying the number of  defective products and the resources that should be optimally allocated to mitigate the defectives items. 
}
\vspace{.1in}\\
\qBrd[4.2in]{atomictangerine!60}{
\item[\sqBullet{atomictangerine}]A broker in a stock exchange speculates how many shares out of 10 newly introduced shares will go up next day. 
}
\vspace{.1in}\\
\qBrd[4.2in]{bazaar!60}{
\item[\sqBullet{bazaar}] A airline company is interested in identifying the number of last minute cancellations that may take place.
}
\vspace{.1in}\\
\qBrd[4.2in]{blush!60}{
\item[\sqBullet{blush}]  A car insurance company have sold 2000 insurance policies on a specific new cars.  They need to estimate the funts that should be made available/reserved to compensate the losses that may occur to the insured cars during the next one year. 
}
\end{itemize}	
\end{frame}

\newcommand{\binP}{\pi}




\TransitionFrame[bittersweet]{\Large Bernoulli Distribution  }

\begin{frame}{A Bernoulli Trial/ Experiment}
\begin{itemize}
\qBrd[4.2in]{atomictangerine!60}{
\item[\sqBullet{atomictangerine}] The random experiment has only two outcomes.  Namely \HLTEQ[green!30]{\text{SUCCESS}}, and  \HLTEQ[white]{\text{FAILURE}}
}
\vspace{.1in}\\
\qBrd[4.2in]{bazaar!60}{
\item[\sqBullet{bazaar}] Events corresponding to the successive trials/experiemnts are statistically independent.
}
\vspace{.1in}\\
\qBrd[4.2in]{blush!60}{
\item[\sqBullet{blush}]  All such trials/experiements  have the {\bf same chance/probability of success}.
}
\end{itemize}	
\vspace{.1in}
%\qBrd[4.6in]{olive!30}{ If a sequence of $n$ independent Bernoulli trials is performed under the same condition,  then the random variable that records the  {\bf total number of successes}    is called the {\bf Binomial Random variable. }
%}
\end{frame}

%
%
%\begin{frame}{Binomial Distribution}
%\begin{itemize}
%\qBrd[4.2in]{olive!30}{
%\item A {\bf Bernoulli experiment} is a random experiment, the outcome of which can be classified in one of two mutually exclusive and
%exhaustive ways, say,  ``1=success" or ``0=failure." Let $ Y$ be the
%number of success on a Bernoulli trial, then $Y$ is called the Bernoulli
%random variable. 
%}
%\vspace{.1in}\\
%\qBrd[4.2in]{teal!30}{
%\item If a sequence of $n$ independent Bernoulli trials is performed under the same condition, we call it a set of n Bernoulli trials a Binomial experiment.
%}
%\end{itemize}
%\end{frame}
%







\begin{frame}{Bernoulli Distribution $\text{Binomial}(n,\binP)$}
\vspace{-.1in}
\define{Bernoulli Distribution ($\text{Bernoulli}(\binP)$)}{
Let $\binP\in (0,1)$. 
A discrete random variable on the support, $\support=\{0,1\}$ is called a {\bf Bernoulli($\binP$) } distribution. The corresponding probability mass function can be represented as 
\HLTW{$$ \pmf(x)= \begin{cases}
\binP& \text{ if   } x= 1, \\
(1-\binP)& \text{ if   } x= 0.
\end{cases}
$$}
}
The above pmf can also be reprrsented as the following: 
$$\HLTEQ[amethyst!50]{ \HLTW{\displaystyle \HLTY{\pmf(x)}:= \binP^x (1-\binP)^{1-x}}}, \text{ for } x \in \support, \text{where } \HLTEQ[teal!30]{ \support=\{ 0, 1\}}$$\\
\vspace{.1in}

\end{frame}



\begin{frame}
\qBrd[4.6in]{ceil!50}{
\begin{center}
Let $X\sim \text{Bernoulli}(\binP)$ 
\end{center}
}\\
\vspace{.5in}

%\qBrd[4.6in]{babyblue!40}{
$\Row{\qBrd[.9in]{amethyst!50}{\text{Mean}\\
\HLTW{E(X)=  \binP} },  \qBrd[1.5in]{amethyst!50}{\text{Variance}\\\HLTW{\text{VAR}(X)=  \binP (1-\binP)}}  , \qBrd[1.7in]{amethyst!50}{\text{MGF}\\\HLTW{\text{M}_{_X}(t)=\left( 1-\binP+\binP e^t\right) }} } $
%}

\vspace{.1in}
\qBrd[4.6in]{antiquefuchsia!50}{
\begin{center}
\qBrd[4.2in]{white!40}{
{
\tiny
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
 & & & & & \\
Bernoulli$(\binP)$ &$ \{0, 1\}$ & ${n \choose x} \binP^x (1-\binP)^{1-x}  $ & $\binP$  & $\binP(1-\binP)$&   $\left( 1-\binP+\binP e^t\right)$   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
}}\end{center}}
\end{frame}


\TransitionFrame[bittersweet]{\Large Binomial Distribution  }


\begin{frame}{A Bernoulli Trial/ Experiment}

{\tiny 
\begin{itemize}
\qBrd[4.2in]{atomictangerine!60}{
\item[\sqBullet{atomictangerine}] The random experiment has only two outcomes.  Namely \HLTEQ[green!30]{\text{SUCCESS}}, and  \HLTEQ[white]{\text{FAILURE}}
}
\vspace{.1in}\\
\qBrd[4.2in]{bazaar!60}{
\item[\sqBullet{bazaar}] Events corresponding to the successive trials/experiemnts are statistically independent.
}
\vspace{.1in}\\
\qBrd[4.2in]{blush!60}{
\item[\sqBullet{blush}]  All such trials/experiements  have the {\bf same chance/probability of success}.
}
\end{itemize}	
}
\vspace{.1in}
\qBrd[4.6in]{olive!30}{ If a sequence of $\HLTW{n}$ independent Bernoulli trials are performed under the same condition,  the random variable that records the \HLTW{ \text{\bf total number of }\HLTEQ[green!30]{\text{ SUCCESS}}}    is called the {\bf Binomial Random variable. }
}\\


\end{frame}

%
%\begin{frame}{Binomial Distribution $\text{Binomial}(n,\binP)$}
%\begin{enumerate}
%\item Given a Binomial experiment consisting of n Bernoulli trials with
%success probability $\binP$, the Binomial random variable X associated
%with this experiment is defined as the number of successes among the
%n trials.
%\item The random variable X has the Binomial Distribution with
%parameters n and $\binP$; denoted by$ X\sim Binomial(n, \binP).$
%
%\item The behavior of Binomial Distribution with different $n$ and $\binP$.
%
%\end{enumerate}
%
%\end{frame}
%




\begin{frame}{Binomial Distribution}
\define{Binomial Experiment}{
An experiment is called a Binomial experiment if it satisfies the following 4 conditions:
\begin{itemize}
\item The experiment consists of $n$ Bernoulli trials.
\item Each trial results in a success (S) or a failure (F).
\item The trials are independent.
\item The probability of a success, $\binP$,  is fixed throughout $n$ trials.
\end{itemize}
}

\vspace{.2in}
\qBrd[4.6in]{ceil!50}{
\Large
\begin{center}
Let $X\sim \text{Binomial}(n , \binP)$ 
\end{center}
}\\
\end{frame}




\begin{frame}{Binomial Distribution $\text{Binomial}(n,\binP)$}
\vspace{-.1in}
\define{Binomial Distribution ($\text{Binomial}(n,\binP)$)}{
Let $\binP\in (0,1)$,  and $n$ be a positive integer. 
A discrete random variable on the support, $\support=\{0,1, 2, \ldots, n\}$ is called a {\bf Binomial($n,\binP$) } if the corresponding probability mass function can be represented as  $\text{Binomial}(n, \binP)$ is given by
$$\HLTEQ[amethyst!50]{ \HLTW{\displaystyle \HLTY{\pmf(x)}:= {n \choose x} \binP^x (1-\binP)^{n-x}}}, \text{ for } x \in \support, \text{where } \HLTEQ[teal!30]{ \support=\{\HLTW{ 0, 1, \ldots,  n}\}}$$\\
}
\vspace{.1in}

\end{frame}


\begin{frame}
\vspace{-.11in}
\qBrd[4.6in]{ceil!50}{
\Large
\begin{center}
Let $X\sim \text{Binomial}(n=2 , \binP=0.2)$ 
\end{center}
}\\

\vspace{2.8in}


\end{frame}





\begin{frame}
\vspace{-.11in}

\qBrd[4.6in]{orange!50}{
\Large
\begin{center}
Let $X\sim \text{Binomial}(n=100 , \binP=0.2)$ 
\end{center}
}\\
\vspace{2.8in}
\end{frame}




\begin{frame}
\vspace{-.1in}
\begin{center}
\includegraphics[scale=.45]{figs/BinomialExpectedValue.png}
\end{center}
\vspace{1in}
\end{frame}




\begin{frame}
\qBrd[4.6in]{ceil!50}{
\begin{center}
Let $X\sim \text{Binomial}(n , \binP)$ 
\end{center}
}\\
\vspace{.5in}

%\qBrd[4.6in]{babyblue!40}{
$\Row{\qBrd[.9in]{amethyst!50}{\text{Mean}\\
\HLTW{E(X)= n \binP} },  \qBrd[1.5in]{amethyst!50}{\text{Variance}\\\HLTW{\text{VAR}(X)= n \binP (1-\binP)}}  , \qBrd[1.7in]{amethyst!50}{\text{MGF}\\\HLTW{\text{M}_{_X}(t)=\left( 1-\binP+\binP e^t\right)^n   }} } $
%}

\vspace{.1in}
\qBrd[4.6in]{antiquefuchsia!50}{
\begin{center}
\qBrd[4.2in]{white!40}{
{
\tiny
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
 & & & & & \\
Binomial$(n, \binP)$ &$ \{0, 1, \ldots, n\}$ & ${n \choose x} \binP^x (1-\binP)^{n-x}  $ & $n\binP$  & $n\binP(1-\binP)$&   $\left( 1-\binP+\binP e^t\right)^n$   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
}}\end{center}}


\end{frame}

{

\setbeamercolor{structure}{fg=brightlavender!80, bg= black!60}

\begin{frame}{Reminder from Unit1: Binomial Series }
\qBrd[4.5in]{babyblue!40}{
Let $a\in \R$ be any real number,  and $n\in\mathbb{Z}_{+}$ be any positive integer, then   $$ \HLTW{\displaystyle (1+a)^n}=  \HLTY{\displaystyle\sum_{y=0}^{n}   {n \choose y  }  a^{y}}$$
$$\HLTW{\displaystyle (1+a)^n} = \HLTY{\displaystyle 1+{n\choose 1}a+{n\choose 2}a^2+  \cdots+ {n\choose {n-1}}a^{n-1}+{n\choose n}a^n}  $$ 
}\\
\vspace{.1in}
%\pause
\qBrd[4.5in]{babyblueeyes!50}{\tiny 
Let $a\in \R$ be any real number,  and $n\in\mathbb{Z}_{+}$ be any positive integer, then   $$ (a+b)^n=  \HLTY{\displaystyle\sum_{y=0}^{n}   {n \choose i  }  a^{y}b^{n-y}}$$
$$(a+b)^n = \HLTY{\displaystyle b^n+{n\choose 1}ab^{n-1}+{n\choose 2}a^2b^{n-2}+  \cdots+ {n\choose {n-1}}a^{n-1}b+{n\choose n}a^n}  $$ 
}
\end{frame}




\begin{frame}{Reminder from Unit1: Binomial Series }
\qBrd[4.5in]{babyblue!40}{
Let $a\in \R$ be any real number,  and $n\in\mathbb{Z}_{+}$ be any positive integer, then 
  $$   \HLTY{\displaystyle\sum_{y=0}^{n}   \HLTW{y} {n \choose y  }   \HLTEQ[amethyst!50]{a}^{y}}= \HLTW{\displaystyle n\;\times   \HLTEQ[amethyst!50]{a}(1+ \HLTEQ[amethyst!50]{a})^{n-1}}$$
}\\
\vspace{.5in}
\qBrd[4.5in]{babyblue!40}{
Let $a\in \R$ be any real number,  and $n\in\mathbb{Z}_{+}$ be any positive integer, then 
$$   \HLTY{\displaystyle\sum_{y=0}^{n}   \HLTW{y^2 } {n \choose y }  \HLTEQ[amethyst!50]{a}^{y}} = \HLTW{\displaystyle  n\; \HLTEQ[amethyst!50]{a}(1+\HLTEQ[amethyst!50]{a})^{n-1} + n(n-1)\; \HLTEQ[amethyst!50]{a}^2(1+\HLTEQ[amethyst!50]{a})^{n-2}  }$$
}\\
\vspace{1in}

\end{frame}

}



\begin{frame}{Expected Value of Binomial Distribution}
\begin{eqnarray}
E(X)& := &  \sum_{y\in \support[X]} y\; \pmf_{_X}(y) \nonumber\\
& = &  \sum_{y=0}^{n} y {n\choose y}\binP^y(1-\binP)^{n-y}  \nonumber\\
& =& (1-\binP)^{n}  \sum_{y=0}^{n}  y {n\choose y}\left(  \HLTEQ[amethyst!50]{ \frac{\binP}{1-\binP}}\right)^y   \nonumber\\
& =& (1-\binP)^{n} \left[  n \HLTEQ[amethyst!40]{ \frac{\binP}{(1-\binP)}}\times\HLTEQ[amethyst!40]{ \left( 1+ \frac{\binP}{1-\binP}\right)^{n-1}} \right] \nonumber\\
& =& (1-\binP)^{n}  \frac{n\binP}{(1-\binP)^n} \nonumber\\
& =& n\binP\nonumber
\end{eqnarray}

\end{frame}


\begin{frame}{Expected Value of Binomial Distribution}
\small
\begin{eqnarray}
& &  E(X^2) \nonumber\\
&:= &  \sum_{y\in \support[X]} y^2\; \pmf_{_X}(y) \nonumber\\
& = &  \sum_{y=0}^{n} y^2 {n\choose y}\binP^y(1-\binP)^{n-y}  \nonumber\\
& =& (1-\binP)^{n} \left[ \sum_{y=0}^{n}  y^2 {n\choose y}\left( \HLTEQ[amethyst!50]{\frac{\binP}{1-\binP}}\right)^y  \right] \nonumber\\
& =&(1-\binP)^{n} \left[  \HLTW{\displaystyle  n\; \HLTEQ[amethyst!50]{\frac{\binP}{1-\binP}}(1+\HLTEQ[amethyst!50]{\frac{\binP}{1-\binP}})^{n-1} + n(n-1)\; \HLTEQ[amethyst!50]{\frac{\binP}{1-\binP}}^2(1+\HLTEQ[amethyst!50]{\frac{\binP}{1-\binP}})^{n-2}  }\right]\nonumber\\
& =& (1-\binP)^{n}  \frac{n\binP+ n(n-1)\binP^2}{(1-\binP)^n} \nonumber\\
& =& n\binP+ n(n-1)\binP^2\nonumber
\end{eqnarray}

\end{frame}
\begin{frame}
\begin{eqnarray}
Var(X) & = &  E(X^2)- (E(X))^2 \nonumber\\
 & =&  n\binP +n(n-1)\binP^2- n^2 \binP^2\nonumber\\
  & =&  n\binP +n^2\binP^2- n\binP^2 - n^2 \binP^2\nonumber\\
 & = &  n\binP-n \binP^2\nonumber\\
 & = & \HLTY{ n\binP (1-\binP)}.\nonumber
\end{eqnarray}
\vspace{1in}
\end{frame}


\begin{frame}{Expected Value of Binomial Distribution}
\begin{eqnarray}
M_X(t) :=   \sum_{y\in \support[X]} e^{ty}\; \pmf_{_X}(y) 
%& = &  \sum_{y=0}^{n} e^{ty} {n\choose y}\binP^y(1-\binP)^{n-y}  \nonumber\\
& =& (1-\binP)^{n}  \sum_{y=0}^{n}  e^{ty} {n\choose y}\left( \frac{\binP}{1-\binP}\right)^y   \nonumber\\
%& =& (1-\binP)^{n}  \sum_{y=0}^{n}  {n\choose y}\left( \frac{\binP e^{t}}{1-\binP}\right)^y   \nonumber\\
& =& (1-\binP)^{n}  \sum_{y=0}^{n}  e^{ty} {n\choose y}\left( \frac{\binP}{1-\binP}\right)^y   \nonumber\\
& =& (1-\binP)^{n}  \left[ \sum_{y=0}^{n}   {n\choose y}\left( \HLTEQ[amethyst!50]{ \frac{\binP e^{t}}{1-\binP}}\right)^y  \right] \nonumber\\
& =& (1-\binP)^{n} \left[\left( 1+ \HLTEQ[amethyst!50]{  \frac{\binP e^t}{1-\binP} }\right)^n\right] \nonumber\\
& =&  \HLTY{\left( 1-\binP+\binP e^t\right)^n }  \nonumber
\end{eqnarray}



\end{frame}






\begin{frame}\frametitle{Example}
\vspace{-.1in}
\qbx[4.5in]{amber!50}{
\Exmpl{amber}{} Five fair coins are  flipped.  If the outcomes are assumed independent.
\begin{enumerate}
\item Find the probability mass function of the number of heads obtained.
\item Find the probability that at least 3 heads are obtained.
\item Find the probability that at most 2 heads are obtained.
\end{enumerate}
}\\
\pause
\vspace{.1in}
{\tiny 
{\bf Solution: }
Let $X$ = The number of heads in 5 tossed coins. $X\sim Binomial(n=5, \binP=0.5)$.
\begin{enumerate}
\item $P(X = 0) =0.5^5 = 0.0313$
\item $P(X = 1) ={5 \choose 1}0.5^5 =0.1563$
\item $P(X = 2) ={5 \choose 2}0.5^5 =0.3125$
\item $P(X = 3) ={5 \choose 3}0.5^5 =0.3125$
\item $P(X = 4) ={5 \choose 4}0.5^5 =0.1563$
\item $P(X = 0) ={5 \choose 5}0.5^5 = 0.0313$
\end{enumerate}
}
\end{frame}


\begin{frame}\frametitle{Example}
\vspace{-.1in}
\qbx[4.5in]{amethyst!50}{
\Exmpl{amethyst}{} It is known that screws produced by a certain company will be defective with probability .01, independently of each other. The company sells the screws in packages of 10 and offers a money-back guarantee that at most 1 of the 10 screws is defective. What proportion of packages sold must the company replace? Use the
Binomial Calculator or Statistical Tables.
}\\
\vspace{1.5in}

\end{frame}


\begin{frame}\frametitle{Example}
\vspace{-.1in}
\qbx[4.5in]{olive!50}{
\Exmpl{olive}{} The following gambling game, known as the wheel of fortune (or chuck-a-luck), is quite popular at many carnivals and gambling casinos: A player bets on one of the numbers 1 through 6. Three dice are then rolled, and if the number bet by the player appears i times, i = 1; 2; 3, then the player wins i units; if the number bet by the
player does not appear on any of the dice, then the player loses 1 unit. Is this game fair to the player?
}\\
\vspace{1.5in}
\end{frame}



\setbeamercolor{structure}{fg=airforceblue!70, bg= black!60}



\section{Poisson Distribution  }


\TransitionFrame[airforceblue]{\Large Poisson Distribution  }

\begin{frame}
\begin{itemize}
\qBrd[4.2in]{amber(sae/ece)!40}{
\item[\sqBullet{amber(sae/ece)}] Number of calls received by a customer desk in an hour.
}
\vspace{.1in}\\
\qBrd[4.2in]{atomictangerine!60}{
\item[\sqBullet{atomictangerine}]Number of imperfections in every square-meter of a glass panel used for making LCD TV.
}
\vspace{.1in}\\
\qBrd[4.2in]{bazaar!60}{
\item[\sqBullet{bazaar}] Number of robot malfunctions per day in an assembly line.
}
\vspace{.1in}\\
\qBrd[4.2in]{blush!60}{
\item[\sqBullet{blush}]  Number of car accidents  in a segment of roads that occurs during a year. 
}
\end{itemize}	

\end{frame}


\begin{frame}\frametitle{Poisson Distribution}
The Poisson distribution models the number of occurrences of an
event when there is a known average rate per unit time or space $\lambda$.

\define{Poisson Distribution}{
The requirements for a Poisson distribution are that:
\begin{enumerate}
\item no two events can occur simultaneously,
\item events occur independently in different intervals, and
\item the expected number of events in each time interval remain constant.
\end{enumerate}
}
\end{frame}


\begin{frame}\frametitle{Poisson Distribution: pmf, Expected Value }
The Poisson distribution models the number of occurrences of an
event when there is a known average rate per unit time or space $\lambda$.

\define{Poisson Distribution}{
 A discrete random variable on the support, $\support= \{0,1,2,3, \ldots\}$,  is called a {\bf  Poisson distribution with mean parameter $\lambda$} if the corresponding probability mass function is specified as \\
 $$
\qBrd[1.3in]{amethyst!30}{$ \displaystyle p(x) = \frac{e^{-\lambda}\lambda^x}{x!}$}  $$ { for } $x = 0, 1, 2, 3, \ldots$,  where  $\lambda>0$. 
}
\end{frame}


\begin{frame}
\qBrd[4.6in]{ceil!50}{
\begin{center}
Let $X\sim \text{Poisson}(\lambda)$ 
\end{center}
}\\
\vspace{.5in}
%\qBrd[4.6in]{babyblue!40}{
$\Row{\qBrd[.9in]{airforceblue!50}{\text{Mean}\\
\HLTW{E(X)= \lambda} },  \qBrd[1.5in]{airforceblue!50}{\text{Variance}\\\HLTW{\text{VAR}(X)=  \lambda}}  , \qBrd[1.7in]{airforceblue!50}{\text{MGF}\\\HLTW{\text{M}_{_X}(t)=e^{ \lambda e^t-  \lambda}    }} } $
%}

\vspace{.1in}
\qBrd[4.6in]{airforceblue!50}{
\begin{center}
\qBrd[4.2in]{white!40}{
{
\small
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
 & & & & & \\
Poisson$( \lambda)$ &$ \{0, 1, 2, \ldots \}$ & $  \frac{e^{-\lambda}\lambda^x}{x!} $ & $ \lambda$  & $ \lambda$&   $e^{ \lambda e^t-  \lambda}  $   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
}}\end{center}}
\end{frame}



\begin{frame}
\vspace{1in}
\includegraphics[scale=.3]{figs/PoissonExample1.png}
\end{frame}

{
\setbeamercolor{structure}{fg=brightlavender!80, bg= black!60}


\begin{frame}\frametitle{Reminder from Unit1: Exponential Series $e^a \text{ or }( \exp(a))$}
\vspace{-.1in}
\define{Exponential Series}{
For any real number $a\in \R$, the exponential series $\HLTY{e^a}$  (or sometimes denoted as $\HLTY{\exp(a)}$) is defined as, 
$$\HLTY{\displaystyle e^{\HLTEQ[amethyst!50]{a}}}=\HLTW{\displaystyle \sum_{n=0}^{\infty}\frac{\HLTEQ[amethyst!50]{a}^n}{n!}} = \HLTY{\displaystyle 1+\frac{\HLTEQ[amethyst!50]{a}}{1!}+\frac{\HLTEQ[amethyst!50]{a}^2}{2!}+ \frac{\HLTEQ[amethyst!50]{a}^3}{3!}+\cdots,}  $$
}

\vspace{2.5in}


\end{frame}



}


\begin{frame}{Expected Value of Binomial Distribution}
\begin{eqnarray}
M_X(t)& := &  \sum_{y\in \support[X]} e^{ty}\; \pmf_{_X}(y) \nonumber\\
& = &  \sum_{y=0}^{\infty} e^{ty} \frac{e^{-\lambda} \lambda^y}{y!} \nonumber\\
%& = &  e^{-\lambda}\sum_{y=0}^{\infty}  \frac{ \left(\HLTEQ[amethyst!50]{ \lambda e^t}\right)^y}{y!} \nonumber\\
& = &  e^{-\lambda} \left[ \sum_{y=0}^{\infty}  \frac{ \left(\HLTEQ[amethyst!50]{ \lambda e^t}\right)^y}{y!} \right] \nonumber\\
& = &  e^{-\lambda }\left[ e^{\lambda e^t} \right]\nonumber\\
& = &  \exp\left[ {\lambda e^t-\lambda}\right] \nonumber
\end{eqnarray}

\vspace{1.5in}


\end{frame}

\begin{frame}

\end{frame}




\begin{frame}\frametitle{ }
\vspace{-.1in}
\begin{enumerate}
\qBrd[4.2in]{chestnut!50}{
\item[\sqBullet{chestnut}]  The number of customers arriving at a service counter within one-hour period.
}\\
\vspace{.1in}
\qBrd[4.2in]{carnationpink!40}{
\item[\sqBullet{carnationpink}] The number of typographical errors in a book counted per page.
}\\
\vspace{.1in}
\qBrd[4.2in]{antiquefuchsia!40}{
\item[\sqBullet{antiquefuchsia}] The number of email messages received at the technical support center daily.
}\\
\vspace{.1in}
\qBrd[4.2in]{chocolate(web)!40}{
\item[\sqBullet{chocolate(web)}] The number of traffic accidents that occur on a specific road  during a month.
}\\
\end{enumerate}
\vspace{.2in}

\end{frame}


\begin{frame}\frametitle{Poisson Process: Most Simple Version
}

\begin{enumerate}
\item The Number of Events Between the interval (can be time-interval or space-interval )  $(s, t]$ follows $$ \text{Poisson}(\lambda\times (t-s))$$
where $\lambda>0$ denotes of rate of events per unit length of the interval. 
\item Events pertaiing to the two distinct intervals are Statistically Independent
\item Rate of occurance of the events remain same for each of the subintervals with same length. 
\end{enumerate}

\end{frame}


\begin{frame}\frametitle{A Few Examples of Poisson Distribution }
\vspace{-.1in}
\qbx[4.5in]{olive!50}{
\Exmpl{olive}{} Messages arrive at an electronic message center at random times, with an average of 9 messages per hour. 
\begin{enumerate}
\item What is the probability of receiving exactly five messages during the next hour?
\item What is the probability that more than 10 messages will be received within the next two hours?
\end{enumerate}
}\\


\vspace{.5in}
{\tiny 
\begin{enumerate}
\item The number of messages received in an hour, $X$ is modeled by
Poisson distribution with $\lambda =  9$, i.e.  $X\sim \text{Poisson}(9)$.
$P(X=5)= \frac{9^5 \exp(-9)}{5!}$
\item The number of messages received within a 2-hour period, $Y$ is
another Poisson distribution with  $Y= (2)(9) =18$, i.e. $Y\sim  \text{Poisson}(18)$.
$P(Y > 10) =1- P(Y\leq 10 )= ...= 0.9696$
\end{enumerate}

}

\end{frame}



%
%\begin{frame}\frametitle{Group Work }
%\begin{enumerate}
%\item Develop a real life example in which you can easily apply:
%\begin{enumerate}
%\item  Group 1: Poisson distribution.
%\item  Group 2: Binomial distribution.
%\item Group 3: Poisson distribution
%\end{enumerate}
%\item  In each case, propose two problems which can be solved using the Statistical Calculator.
%\item Can you propose an idea in which you can mix both distributions?
%(extra)
%\end{enumerate}
%
%\end{frame}




\setbeamercolor{structure}{fg=cambridgeblue!90, bg= black!60}
\section{Geometric Distribution   }
\TransitionFrame[cambridgeblue]{\Large Geometric Distribution}



\begin{frame}\frametitle{Geometric Distribution}
\vspace{-.1in}
\begin{enumerate}
\item Suppose that independent trials, each having a probability $\binP$,
$0 < \binP <1$, of being a success, are performed until a success occurs.
\item Example: The first head in tossing coin several times.
\item Then, Geometric distribution models the number of trials performed until a success occurs.
\end{enumerate}

\define{Geometric Distribution}{
A discrete random variable on the support $\support=\{1,2,3, \ldots \}$ is defined to be the {\bf Geometric($\binP$)}  random variable if the corresponding probability mass function can be represented as the following 
$$\HLTW{\displaystyle p(x) =\binP (1-\binP)^{x-1} }\text{ for } x = 1, 2, 3, \ldots, $$
where $0<\binP<1$.
}

%\qBrd[4.7in]{olive!40}{
%\sqBullet{olive} If $X\sim \text{Geometric}(\binP)$ then $E(X)= \frac{1}{\binP}$, and $\text{Var}(X)= \frac{1-\binP}{\binP^2}$
%}


\end{frame}



\begin{frame}

\qBrd[4.7in]{olive!40}{
\begin{center}
Let $X\sim \text{Geometric}(\binP)$ 
\end{center}
}\\

\vspace{.5in}
%\qBrd[4.6in]{babyblue!40}{
$\Row{\qBrd[.9in]{asparagus!50}{\text{Mean}\\
\HLTW{E(X)= \frac{1}{\binP} } },  \qBrd[1.5in]{asparagus!50}{\text{Variance}\\\HLTW{\text{VAR}(X)=   \frac{1- \binP}{\binP^2}}}  , \qBrd[1.7in]{asparagus!50}{\text{MGF}\\\HLTW{\text{M}_{_X}(t)= \frac{\binP e^t}{1-(1-\binP)e^{t}}    }} } $
%}

\vspace{.1in}
\qBrd[4.6in]{asparagus!50}{
\begin{center}
\qBrd[4.2in]{white!40}{
{
\tiny
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
 & & & & & \\
Geometric$( \binP)$ &$ \{1, 2, \ldots \}$ & $\binP (1-\binP)^{x-1}  $ & $ \frac{1}{\binP} $  & $ \frac{1-\binP}{\binP^2} $&   $ \frac{ {\binP} e^t}{1-(1-\binP) e^{t}}    $   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
}}\end{center}}
\end{frame}


{
\setbeamercolor{structure}{fg=brightlavender!80, bg= black!60}

\begin{frame}\frametitle{Reminder from Unit1: Geometric Series}
\qBrd[4.5in]{babyblue!50}{
Let $ \HLTEQ[amethyst!40]{p} \in \R$ be such that $\abs{\HLTEQ[amethyst!40]{p}}<1$,  then   $$ \HLTY{\displaystyle \sum_{y=0}^{\infty}\HLTEQ[amethyst!40]{p}^{y}}= \HLTW{\displaystyle 1+\HLTEQ[amethyst!40]{p}+\HLTEQ[amethyst!40]{p}^2+\HLTEQ[amethyst!40]{p}^3+  \cdots}   =\HLTY{\displaystyle \frac{1}{1-\HLTEQ[amethyst!40]{p}}}.$$ 
}
\begin{enumerate}
\vspace{.1in}
\item What is the value of $\HLTY{1+0.7+(0.7)^2 + (0.7)^3+ \cdots =}$\\
\vspace{.1in}
\item What is the value of $\HLTY{1-0.7+(0.7)^2 - (0.7)^3+ \cdots =}$
\end{enumerate}
\vspace{3in}
\end{frame}





\begin{frame}\frametitle{Reminder from Unit1: Geometric Series}
\qBrd[4.5in]{babyblue!50}{
Let $ \HLTEQ[amethyst!40]{p} \in \R$ be such that $\abs{\HLTEQ[amethyst!40]{p}}<1$,  then   $$  \HLTW{\HLTY{\displaystyle \sum_{y=0}^{\infty}\HLTEQ[white!40]y {\HLTEQ[amethyst!40]{p}}^{y}} =\HLTY{\displaystyle \frac{\HLTEQ[amethyst!40]{p}}{\left( 1-\HLTEQ[amethyst!40]{p}\right)^2  }}}$$ 
}\\
\vspace{.2in}
\qBrd[4.5in]{ceil!50}{
Let $ \HLTEQ[amethyst!40]{p} \in \R$ be such that $\abs{\HLTEQ[amethyst!40]{p}}<1$,  then   $$ \HLTW{ \HLTY{\displaystyle \sum_{y=0}^{\infty}\HLTEQ[white!40]y^2 {\HLTEQ[amethyst!40]{p}}^{y}} =\HLTY{\displaystyle \frac{\HLTEQ[amethyst!40]{p}}{\left( 1-\HLTEQ[amethyst!40]{p}\right)^2  }}+ \HLTY{\displaystyle \frac{\HLTEQ[amethyst!40]{2p^2}}{\left( 1-\HLTEQ[amethyst!40]{p}\right)^3 }}}$$ 
}

\vspace{3in}
\end{frame}


}




\begin{frame}{Expected Value of Geometric Distribution}
\begin{eqnarray}
M_X(t)=   \sum_{x\in \support[X]} e^{tx}\; \pmf_{_X}(x)
& = &  \sum_{x=1}^{\infty }\; e^{tx}  (1-\binP)^{x-1}\binP \nonumber\\
& = & \binP   \sum_{y=0}^{\infty } e^{ty+t}  (1-\binP)^{y} \nonumber\\
& = &  \binP e^t   \left[  \sum_{y=0}^{\infty } \left(  \HLTEQ[amethyst!50]{(1-\binP)e^{t}}\right)^y \right]\nonumber\\
& = &\binP e^t \left[  \frac{1}{1-\HLTEQ[amethyst!50]{(1-\binP)e^{t}   }} \right] \nonumber\\
& = & \HLTY{ \frac{\binP e^t }{1-\HLTEQ[amethyst!50]{(1-\binP)e^{t}   }}}  \nonumber
\end{eqnarray}



\end{frame}






\begin{frame}\frametitle{Geometric Distribution: Example}
\vspace{-.1in}
\qbx[4.5in]{apricot!50}{
\Exmpl{apricot}{}  
Of a population of consumers, 60\% are reputed to prefer a particular brand, A, of toothpaste. If a group of randomly selected consumers is interviewed, 
\begin{enumerate}
\item what is the probability that {\bf exactly five }  people have to be interviewed to encounter the first consumer who prefers brand A?
\item  what is the probability that {\bf at least }  five people have to be interviewed to encounter the first consumer who prefers brand A?
\end{enumerate}	
}
\vspace{1in}
\end{frame}
%
%
%\begin{frame}\frametitle{Geometric Distribution: Example}
%\vspace{-.1in}
%\qbx[4.5in]{olive!50}{
%\Exmpl{olive}{}  Suppose that the probability of engine malfunction during any one-hour period is $\binP = 0.02$. Find the probability that a given engine will survive two hours.
%}\\
%\pause
%
%\vspace{.1in}
%{\tiny Solution: \\
%Letting $Y$ denote the number of one-hour intervals until the first
%malfunction, we have 
%\begin{eqnarray}
%& & P(\text{Survival for Next Two Hours})\nonumber\\
%& =&  P(Y\geq 3)\nonumber\\
%& =& 1- P(Y\leq 2)\nonumber\\
%& = &1-   \sum_{y=1}^{2}p(y)\nonumber\\
%& = &1-   \left\{ p(1)+p(2)\right\}\nonumber\\
%& =& 1-0.02-0.98\times 0.02\nonumber\\
%& =& 0.9604\nonumber
%\end{eqnarray}
%}
%\qBrd[4.5in]{babyblue!70}{
%\HLTW{\text{Exercise}}
% Find the mean and standard deviation of Y.
%}
%
%\end{frame}
%







\setbeamercolor{structure}{fg=cadmiumorange!80, bg= black!60}
\section{Negative Binomial Distribution }
\TransitionFrame[cadmiumorange]{\Large Negative Binomial Distribution  }


\begin{frame}
\begin{enumerate}
\item Suppose that independent trials, each having probability  $\binP$,
$0 < \binP < 1$, of being a success are performed until a total of r
successes is accumulated.
\item  Example: The third head in tossing coin several times.

\item  Then, Negative Binomial distribution models the number of trials
performed until a the rth success occurs.
\end{enumerate}

\define{Negative Binomial Distribution}{
Let $\binP \in (0,1)$ and $r$ be a positive integer. 
A discrete random variable on the support $\support=\{r+1,r+2,r+3, \ldots \}$ is defined to be the {\bf Negative-Binomial($r, \binP$)}  random variable if the corresponding probability mass function can be represented as 
$$\HLTW{ \displaystyle p(x) ={{x-1}\choose{r-1}}\binP^{r} (1-\binP)^{x-r} }\text{ for } x = r+1, r+2,r+ 3, \ldots, $$
}

%\qBrd[4.7in]{olive!40}{
%\sqBullet{olive} If $X\sim \text{Negative-Binomial}(r, \binP)$ then $E(X)= \frac{r}{\binP}$, and $\text{Var}(X)= \frac{r(1-\binP)}{\binP^2}$
%}


\end{frame}






\begin{frame}
\qBrd[4.7in]{amber!40}{
\begin{center}
Let $X\sim \text{Negative-Binomial}(r, \binP)$
\end{center}
}\\

\vspace{.5in}
%\qBrd[4.6in]{babyblue!40}{
$\Row{\qBrd[.9in]{carrotorange!50}{\text{Mean}\\
\HLTW{E(X)= \frac{r}{\binP} } },  \qBrd[1.5in]{carrotorange!50}{\text{Variance}\\\HLTW{\text{VAR}(X)=   \frac{r(1- \binP)}{\binP^2}}}  , \qBrd[1.7in]{carrotorange!50}{\text{MGF}\\\HLTW{\text{M}_{_X}(t)=\left( \frac{\binP e^t}{1-(1-\binP)e^{t}}\right)^r    } } } $
%}

\vspace{.1in}
\qBrd[4.75in]{carrotorange!70}{
\begin{center}
\qBrd[4.7in]{white!40}{
{
\tiny
\begin{tabular}{|c|c|c|c|c|c|}
\hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
 & & & & & \\
Negative-Binomial$(r,  \binP)$ &$ \{r+1, r+2, \ldots \}$ & $ {{x-1}\choose{r-1}}\binP^{r}(1-\binP)^{x-r}  $ & $ \frac{r}{\binP} $  & $ \frac{r(1-\binP)}{\binP^2} $&   $\left( \frac{  \binP e^t}{1-(1-\binP) e^{t}}  \right)^r  $   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
}}\end{center}}
\end{frame}





\begin{frame}\frametitle{Geometric Distribution: Example}
\vspace{-.1in}
\qbx[4.5in]{amber!50}{
\Exmpl{amber}{}{
It is known that a machine produces 1\% defective parts. What is the probability that
\begin{enumerate}
\item 10 parts have to be selected until to get 2 defective parts.
\item Between 20 to 25 parts have to be selected to get 2 defective parts.
\end{enumerate}
}  
}\\
%\pause

\vspace{1in}
{\tiny Solution: \\

}
\qBrd[4.5in]{babyblue!70}{
\HLTW{\text{Exercise}}
 Find the mean and standard deviation of Y.
}

\end{frame}




\begin{frame}
\tiny
%\hspace{-1.5in}
%\qBrd[7.2in]{antiquefuchsia!50}{\vspace{-.35in}
%\begin{center}
%\qBrd[4.9in]{apricot!80}{ \begin{center} \bf \Large Standard Properties of  a few Discrete Distributions \end{center} }
%\end{center}
%\begin{center}
%\qBrd[6.99in]{white!40}{
%{
\begin{tabular}{|c|c|c|c|c|c|}
\hline
  \hline
 Distribution & Support  &  pmf    & Mean   &  Variance  & mgf   \\
& $\support[X]$  &   $\pmf_{_X}(x)$   &  $E(X)$  &   $\text{Var}(X)$  &  $M_{_X}(t)$  \\
 \hline \hline
  & & & & & \\
Bernoulli$(\binP)$ &$ \{0, 1\}$ & $ \binP^x (1-\binP)^{1-x}  $ & $\binP$  & $\binP(1-\binP)$&   $\left( 1-\binP+\binP e^t\right)$   \\
 & & & & & \\
 \hline
 \hline
 & & & & & \\
Binomial$(n, \binP)$ &$ \{0, 1, \ldots, n\}$ & ${n \choose x} \binP^x (1-\binP)^{n-x}  $ & $n\binP$  & $n\binP(1-\binP)$&   $\left( 1-\binP+\binP e^t\right)^n$   \\
 & & & & & \\
 \hline
 \hline
 & & & & & \\
Poisson$( \lambda)$ &$ \{0, 1, 2, \ldots \}$ & $  \frac{e^{-\lambda}\lambda^x}{x!} $ & $ \lambda$  & $ \lambda$&   $e^{ \lambda e^t-  \lambda}  $   \\
 & & & & & \\
 \hline
  \hline
   & & & & & \\
  Geometric$( \binP)$ &$ \{1, 2, \ldots \}$ & $ (1-\binP)^{x-1}\binP  $ & $ \frac{1}{\binP} $  & $ \frac{1-\binP}{\binP^2} $&   $ \frac{ {\binP} e^t}{1-(1-\binP) e^{t}}    $   \\
 & & & & & \\
 \hline
 \hline 
 & & & & & \\
Negative-Binomial$(r,  \binP)$ &$ \{r+1, r+2, \ldots \}$ & $ {{x-1}\choose{r-1}}(1-\binP)^{x-r}\binP^{r}  $ & $ \frac{r}{\binP} $  & $ \frac{r(1-\binP)}{\binP^2} $&   $\left( \frac{  \binP e^t}{1-(1-\binP) e^{t}}  \right)^r  $   \\
 & & & & & \\
 \hline
  \hline
\end{tabular}
%}}\end{center}}
\end{frame}



\setbeamercolor{structure}{fg=antiquefuchsia!80, bg= black!60}
\section{Miscellaneous Problems}

\TransitionFrame[antiquefuchsia]{\Large Miscellaneous Problems  }


\begin{frame}
\qBrd[4.5in]{babyblue!30}{
If $X\sim \text{Binomial}(n=50, \binP=0.1)$ then
\begin{enumerate}
\item Obtain the value of $E(X)$, $\text{Var}(X)$, and $ E(X^2) $.
\item What is the MGF of X?
\end{enumerate} 
}
\vspace{2in}
\end{frame}


\begin{frame}
\qBrd[4.5in]{babyblue!30}{
If $X\sim \text{Geometric}(\binP=0.2)$ then
\begin{enumerate}
\item Obtain the value of $E(X)$, $\text{Var}(X)$, and $ E(X^2) $.
\item What is the MGF of X?
\end{enumerate} 
}
\vspace{2in}
\end{frame}




\begin{frame}
\qBrd[4.5in]{babyblue!30}{
If $X\sim \text{Poisson}(\lambda=5)$,  then
\begin{enumerate}
\item Obtain the value of $E(X)$, $\text{Var}(X)$, and $ E(X^2)$
\item What is the MGF of X?
\end{enumerate} 
}
\vspace{2in}
\end{frame}


\begin{frame}
{Identify the distribution from the MGF  (Using the uniqueness property of MGF)}

\qBrd[4.5in]{amethyst!30}{ $M_{X}(t)= (0.7 + 0.3e^t)^4$,  What is the distribution of $X$?}\\
\vspace{.1in}

\qBrd[4.5in]{amethyst!30}{ $M_{X}(t)= \frac{0.9e^t}{ 1 - 0.1 e^t}$,  What is the distribution of $X$? }\\
\vspace{.1in}

\qBrd[4.5in]{amethyst!30}{ $M_{X}(t)= \exp{\left(7e^t-7\right)}$,  What is the distribution of $X$? }
\vspace{.1in}

\qBrd[4.5in]{amethyst!30}{ $M_{X}(t)= \frac{1}{8}(1 + e^t)^3$,  What is the distribution of $X$? }\\
\vspace{.1in}

\qBrd[4.5in]{amethyst!30}{ $M_{X}(t)= \frac{8e^t}{ 10 - 2 e^t}$,  What is the distribution of $X$? }\\
\vspace{.1in}

\end{frame}



\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{olive!30}{
\Exmpl{olive}{}{
Approximately 10\% of the glass bottles coming off a production line have serious flaws in the glass. If two bottles are randomly selected, find the mean and variance of the number of bottles
that have serious flaws.
}  
}\\
\vspace{2.5in}

\end{frame}








\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{airforceblue!30}{
\Exmpl{airforceblue}{}{
Cars arrive at a toll both according to a Poisson process with mean 80 cars per hour. If the
attendant makes a one-minute phone call, what is the probability that at least 1 car arrives
during the call?
}  
}\\
\vspace{2.4in}
\end{frame}








\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{teal!30}{
\Exmpl{teal}{}{
Suppose that a lot of  electrical fuses contains 5\% defectives. If a sample of 5 fuses is tested, find the probability of observing at least one defective.
}  
}\\
\vspace{2.6in}
\end{frame}




\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{amber!30}{
\Exmpl{amber}{}{
An oil exploration firm is formed with enough capital to finance ten explorations. The probability of a particular exploration being successful is 0.10  . Assume the explorations are independent.
\vspace{-.1in}
\begin{enumerate}
\item Find the mean and variance of the number of successful explorations.
\item Suppose the firm has a fixed cost of \$20,000 in preparing equipment prior
to doing its first exploration. If each successful exploration costs \$30,000 and each unsuccessful
exploration costs \$15,000, find the expected total cost to the firm for its ten explorations.
\end{enumerate}
}  
}\\

\vspace{2in}
\end{frame}


\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{blue!25}{
\Exmpl{blue!50}{}{
A food manufacturer uses an extruder (a machine that produces bite-size cookies and snack food) that yields revenue for the firm at a rate of \$200 per hour when in operation.  However, the
extruder breaks down an average of two times every day it operates. If Y denotes the number of breakdowns per day, the daily revenue generated by the machine is $\HLTW{R=1600-50Y^2}$. Find the expected daily revenue for the extruder.
}  
}\\

\vspace{2in}
\end{frame}



\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{babyblue!30}{
\Exmpl{babyblue!80}{}{ A particular sale involves four items randomly selected from a large lot that is known to contain 10\% defectives.  Let Y denote the number of defectives among the 20 sold. The purchaser of the items will return the defectives for repair, and the repair cost is given by $\HLTW{\text{Cost} = 3Y^2 + Y + 2}$.  Find the expected repair cost.
}  
}\\

\vspace{2in}
\end{frame}



\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{teal!40}{
\Exmpl{teal!30}{}{ 
You throw darts at a board until you hit the center area. Your probability of hitting the center area is  $0.17$.  You want to find the probability that it takes eight throws until you hit the center. What values does  X take on? 
}  
}\\

\vspace{2in}
\end{frame}





\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{apricot!40}{
\Exmpl{apricot!80}{}{ In a certain population,  it is known that 80\% of the individuals have the Rhesus (Rh) factor present in their blood.   
\begin{enumerate}
\item If 5 volunteers are randomly selected from the population, what is the probability that at least one does not have the Rh factor?
\item If five volunteers are randomly selected, what is the probability that at most four have the Rh factor?
\end{enumerate}
}  
}\\

\vspace{2in}
\end{frame}



\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{amethyst!30}{
\Exmpl{amethyst!80}{}{ \small Consider rolling a fair dice multiple times untill the first 6 appears.  
\begin{enumerate}
\item Find the expected number of throws required to get the first 6.
\item What is the probability that more then 8 throws are required to obtain the first 6? 
\end{enumerate}
}  
}\\

\vspace{2in}
\end{frame}






\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{asparagus!30}{
\Exmpl{asparagus!80}{}{ \small A tollbooth operator has observed that cars arrive randomly at a rate of 360 cars per hour
\begin{enumerate}
\item what is the probability that exactly two cars will come during a specific one-minute period?
\item Find the probability that 40 cars arrive between 10 am to 10:10 am 
\item Find the expected number of cars between 10 am to 10:10 am
\end{enumerate}
}  
}\\

\vspace{2in}
\end{frame}






\begin{frame}\frametitle{}
\vspace{-.1in}
\qbx[4.5in]{asparagus!30}{
\Exmpl{asparagus!80}{}{ \small A certain type of tree has seedlings randomly dispersed in a large area, with the mean
density of seedlings being approximately five per square yard. If a forester randomly locates ten 1-square-yard sampling regions in the area.  Find the probability that none of the regions will contain seedlings.
}  
}\\

\vspace{2in}
\end{frame}


\begin{frame}
\vspace{-.1in}
\qbx[4.5in]{amber!30}{
\Exmpl{amber!80}{}
Accident records collected by an automobile insurance company give the following information. The probability that an insured driver has an automobile accident is .15. If an accident has occurred, the damage to the vehicle amounts to 20\% of its market value with a probability of 0.80, to 60\% of its market value with a probability of 0.12, and to a total loss with a probability of .08. What premium should the company charge on a 120,000 AED car so that the expected gain by the company is zero?
}
\vspace{1in}
\end{frame}


\TransitionFrame[antiquefuchsia]{\Large Questions?  }
 
 
\end{document}
