\documentclass[12pt]{article}
\input{../MacroDefs/HeaderAssignment}
\usepackage{tfrupee}
 \begin{document}
 
\title{Problem Set 2 }%replace X with the appropriate number
\author{STAT 380\\
UAEU} %if necessary, replace with your course title
%\date{ $ 26^{th} $ August, 2019}
\date{}
 \maketitle\vspace{-.4in}
 \noindent
% \TextInBox{6 in }{Name: \vspace{.22 in}}\\
%\; \TextInBox{6.05 in }{ Enrolled As: \MCOption[1.2in]{PHD Student} \MCOption[1in]{RA}\MCOption[1 in]{TA}}\\
\TextInBox{6 in }{ 
This is a  Student's Activity Task containing a few multiple type questions and a number of  descriptive type problems.  The activity is not a graded component of the course.  Its  objective is to encourage students  learning while solving problems and also to prepare for the upcoming exam.  
  }\\
 \vspace{.4in}
 
 
 


\DefBoxOne{}{
\begin{center}\color{black}
Part I:  Short answer type questions.
\end{center}
}


 {\Large Must Review: Review All the Quiz Problems. Also Review all the problems in the problem set that we have circulated before the midterm.}
\begin{enumerate}
 \item \QuizQ{ \TextInBoxOne{5.4in}{
If we consider a  Dataset that has 100 observations and 170 covariates ( independent variables) to model a continuous response variable.  Identify whether the following statement is True or False.\\
 {\bf Statement: } If we consider a principal component analysis of the data, no more than 100 eigenvalues of the corresponding variance covariance matrix can be  positive. 
}}{
Ans:\MCOption{TURE} \MCOption{FALSE}
}\\


\item \QuizQ{ \TextInBoxOne{5.4in}{
 {\bf Statement}:   `single-linkage' is a criteria used to identify the distance between two clusters based on the  distances of each pair of points that are located withing different clusters.  
}}{
Ans:\MCOption{TURE} \MCOption{FALSE}
}\\



\item \QuizQ{ \TextInBoxOne{5.4in}{
 {\bf Statement: }  To start a K-Means clustering algorithm we need to specify the number of clusters the data may have. 
}}{
Ans:\MCOption{TURE} \MCOption{FALSE}
}\\


%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Consider a dataset with 7 covariates (explanatory variables) to model a continuous response variable.  Six  among the seven covariates are numerical in nature while one of the covariate, `Highest Education level' is categorical variable that can take either of the following four values:\\
%$$\{\text{ High-School}, \text{Bachelor's degree}, \text{Master's Degree}, \text{PHD or Higher} \}$$
%Note that, it is customary to introduce appropriate (multiple) `dummy variables' as covariates to incorporate  categorical. Categorical Covariates.  How many total regression coefficients, including the intercept,  are there in the constructed model ?
%}}{
%Ans:\MCOption[1in]{7}\MCOption[1in]{11}  \MCOption[1in]{10}\MCOption[1in]{9}
%}\\

%*055*11#1

\item \QuizQ{ \TextInBoxOne{5.4in}{
Under which of the following conditions is k-fold cross-validation the same as leave-one-out cross-validation?
}}{
\MCOption[1.5in]{The training set and test-set have the same number of examples} \\
\MCOption[1.5in]{k=1}
 \MCOption[1.5in]{ k=n } 
 \MCOption[1.5in]{ None of the above} 
}\\

\item \QuizQ{ \TextInBoxOne{5.4in}{
Which one of the following is the main reason for pruning a Decision Tree?
}}{
Ans:\\
\MCOption[5in]{T o save computing time during testing} 
\\\MCOption[4.8in]{To save space for storing the Decision Tree}
\\\MCOption[4.8in]{To make the training set error smaller}
\\\MCOption[4.8in]{To avoid over fitting the training set}
}\\

\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider the dendrogram: \\
\begin{center}
\includegraphics[scale=.3]{dend1.png}
\end{center}
Using this dendrogram to create 3 clusters, what would the clusters be?
}}{
\MCOption[2.5in]{\{BA,NA\},\{RM,FI\},\{MI,TO\}} 
\MCOption[2.5in]{\{NA,RM\},\{BA,FI\},\{MI,TO\}} \\
\MCOption[2.5in]{\{BA,NA,RM,FI\},\{MI\},\{TO\}} 
\MCOption[2.5in]{\{BA,NA,RM\},\{FI\},\{MI, TO\}} \\
}\\


%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%One of the primary assumptions of the standard linear regression is the Normality of the corresponding errors.  Based on the the visual inspection of the standard  residual plot, a practitioner suspects that the assumption on the  independence of the model errors may not be satisfied for the dataset.  Therefore,  he/she conducts the standard Durbin-Watson Test of the corresponding residuals and obtained a p-value of $0.37$.  What can be concluded from the above information:
%}}{
%Ans:\\
%\MCOption[5in]{The  model residuals may not be correlated.  } \\
% \MCOption[5in]{There is a Strong Statistical Evidence that the residuals are correlated. }
% \MCOption[5in]{There is a some Statistical Evidence that the residuals are correlated. }
%}\\

% 
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%In the context of Standard Linear Regression to model a continuous response variable, how do we check if there is 'Influential' point in the dataset. 
%}}{Ans: \\
% \MCOption[5in]{It is a Influential point if the corresponding Cook's Distance is more than 0.5. }
%\MCOption[5in]{It is a Influential point if the corresponding Cook's Distance is less than 0.5. }
%\MCOption[5in]{It is a Influential point if the corresponding Cook's Distance is less than 0.05. }
%}\\


%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Question whether to apply logistic regression or Linear Regression
%}}{
%
%}\\


%\item \QuizQ{ \TextInBoxOne{5.4in}{
%{\bf Statement: } AIC BASED model selection
%}}{
%Ans:\MCOption{TURE} \MCOption{FALSE}
%}\\



%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%If we consider a 3 degree regression splines with 7 knot points, then how many regression coefficient parameters are there in the model? (i.e.  what is the dimension of the model?)
%}}{
%Ans:\MCOption[1in]{20}\MCOption[1in]{11}  \MCOption[1in]{9}\MCOption[1in]{10}
%}\\

%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Calculate Complete Linkage
%}}{
%Ans:\MCOption[1in]{24}\MCOption[1in]{16}  \MCOption[1in]{30}\MCOption[1in]{76}
%}\\


%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Two different set of knots
%}}{
%
%}\\

%\item \QuizQ{ \TextInBoxOne{5.4in}{ Let $\pi\in (0,1)$ such that  $\text{Logit}(\pi)=1.12$.  What is the most appropriate value of $\pi$ from the list below. 
%}}{
%\MCOption[1in]{$0.543$}  \MCOption[1in]{$0.97$} \MCOption[1in]{$0.754$}\MCOption[1in]{$3.065$}
%}\\
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{ Let $x$ be a real number such that  $\text{Expit}(x)=0.65$.  What is the most appropriate value of $x$ from the list below. 
%}}{
%\MCOption[1in]{$0.268$}  \MCOption[1in]{$-0.187$} \MCOption[1in]{$1.916$}\MCOption[1in]{$3.065$}
%}\\
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{ Let $\pi\in (0,1)$ such that  $\text{Logit}(\pi)=2.5$.  What is the most appropriate value of $\text{Odds}(\pi)$ from the list below. 
%}}{
%\MCOption[1in]{$0.924$}  \MCOption[1in]{$12.18$} \MCOption[1in]{$0.397$}\MCOption[1in]{$9.11$}
%}\\

\item \QuizQ{ \TextInBoxOne{5.4in}{ In order to model a multi-category response variable, a classification tree is utilized.  Let the response variable can take only 4 categories.  During the modeling, a specific terminal node of the tree has the corresponding proportion/ probabilities to be $\hat{\pi}=(0.1, 0.8, 0.04, 0.06)^T$ to the different response categories for the points assigned to it.  Calculate the 
Gini's Index for the obtained probability vector.
}}{
Ans: \vspace{.5in}
}\\

\item \QuizQ{ \TextInBoxOne{5.4in}{ In order to model a multi-category response variable, a classification tree is utilized.  Let the response variable can take only 4 categories.  During the modeling, a specific terminal node of the tree has the corresponding proportion/ probabilities to be $\hat{\pi}=(0.08, 0.81, 0.05, 0.06)^T$ to the different response categories for the points assigned to it.  Calculate the 
Cross-Entropy Index for the obtained probability vector.
}}{
Ans: \vspace{.5in}
}\\


\item \QuizQ{ \TextInBoxOne{5.4in}{ In order to model a multi-category response variable, a classification tree is utilized.  Let the response variable can take only 4 categories.  During the modeling, a specific terminal node of the tree has the corresponding proportion/ probabilities to be $\hat{\pi}=(0.15, 0.1 0.65, 0.1)^T$ to the different response categories for the points assigned to it.  Calculate the 
mis-classification rate for the obtained probability vector.
}}{
Ans: \vspace{.5in}
}\\
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%In a game of rolling a fair dice twice. A player wins if both throws result in  sixes. What is the odds of winning the game?
%}}{
%Ans:  \MCOption[1in]{$\frac{1}{36}$}\MCOption[1in]{$\frac{1}{6}$}  \MCOption[1in]{$\frac{1}{35}$}\MCOption[1in]{$\frac{35}{36}$}
%}\\
%
%
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Imagine we have a sample of 150 points, 70 from ‘Class 0’ ( For example: healthy) and the others from ‘Class 1 ( For Example: Not Healthy). Let us assume that a classification technique (Medical Testing) can correctly identify 65 out of the 70 belongs to the ‘Class 0’ (positive for all Diseased) while it can correctly detect 77 of objects that belongs to the ’Class1’(Not Healthy). Calculate the {\bf Sensitivity}  for the corresponding Classification Technique. 
%}}{
%\MCOption[1in]{$96.25\%$}\MCOption[1in]{$91.31\%$}  \MCOption[1in]{$92.92\%$}\MCOption[1in]{$93.90\%$}
%}\\
%
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Imagine we have a sample of 150 points, 70 from ‘Class 0’ ( For example: healthy) and the others from ‘Class 1 ( For Example: Not Healthy). Let us assume that a classification technique (Medical Testing) can correctly identify 65 out of the 70 belongs to the ‘Class 0’ (positive for all Diseased) while it can correctly detect 77 of objects that belongs to the ’Class1’(Not Healthy). Calculate the {\bf Specificity}  for the corresponding Classification Technique. 
%}}{
%\MCOption[1in]{$96.25\%$}\MCOption[1in]{$95.59\%$}  \MCOption[1in]{$92.85\%$}\MCOption[1in]{$93.90\%$}
%}\\
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Imagine we have a sample of 150 points, 70 from ‘Class 0’ ( For example: healthy) and the others from ‘Class 1 ( For Example: Not Healthy). Let us assume that a classification technique (Medical Testing) can correctly identify 65 out of the 70 belongs to the ‘Class 0’ (positive for all Diseased) while it can correctly detect 77 of objects that belongs to the ’Class1’(Not Healthy). Calculate the {\bf Yuden Index } for the corresponding Classification table. 
%}}{
%\MCOption[1in]{$0.891$}\MCOption[1in]{$0.938$}  \MCOption[1in]{$0.929$}\MCOption[1in]{$1.86$}
%}\\
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Imagine we have a sample of 150 points, 70 from ‘Class 0’ ( For example: healthy) and the others from ‘Class 1 ( For Example: Not Healthy). Let us assume that a classification technique (Medical Testing) can correctly identify 65 out of the 70 belongs to the ‘Class 0’ (positive for all Diseased) while it can correctly detect 77 of objects that belongs to the ’Class1’(Not Healthy). Calculate the Yuden Index for the corresponding Classification table. 
%}}{
%\MCOption[1in]{$0.891$}\MCOption[1in]{$0.938$}  \MCOption[1in]{$0.929$}\MCOption[1in]{$1.86$}
%}\\
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Consider analyzing a data-set that has a binary categorical response while all the covariates are numerical and continuous in nature.  We know that a logistic regression and also a quadratic discriminant analysis is applied for  modeling the response variable.  To compare the performance of both the method a ROC curve is constructed and the corresponding Area Under the ROC Curve (AUC) is calculated based on their performance in a Testing set. The AUC for the logistic regression is 0.91 while the AUC for the QDA is 0.85.  Identify whether the following statement is TRUE or FALSE. 
%{\bf Statement: } The Logistic regression is performing bettern then that of the QDA for this data set that is evaluated based on the testing set. 
%}}{
%\MCOption[1in]{TRUE}\MCOption[1in]{FALSE} 
%}\\
%
%
%
%





\end{enumerate}


\newpage
 
 
 
 

\DefBoxOne{}{
\begin{center}\color{black}
Part II:  Descriptive Problems. 
\end{center}
}
%\DefBoxOne{Notations}{
%$$ \Onebf_k=\left[ \begin{array}{c}1\\1\\\vdots \\1\end{array}\right]_{k\times 1} \text{ , }  J_{k}=\left[ \begin{array}{cccc}1&1 & \cdots & 1\\1& 1& \cdots&  1\\\vdots & \vdots & \ddots  &\vdots \\1& 1 &\cdots & 1\end{array}\right]_{k\times k} \text{ and } I_{k}=\left[ \begin{array}{cccc}1&0 & \cdots & 0\\0& 1& \cdots&  0\\\vdots & \vdots & \ddots  &\vdots \\0& 0 &\cdots & 1\end{array}\right]_{k\times k} \text{ for } k\in \Z_{+}.   $$
%
%}
\begin{enumerate}
\item {\Large Must Review: Review All the Quiz Problems. Also Review all the problems in the problem set that we have circulated before the midterm.}
\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider a clustering problem of bi-variate data with the following distance matrix: \\
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|}
\hline
 & A   & B   & C   & D   & E   \\ \hline
A & 0   & 6.5 & 2.4 & 4.2 & 5.9 \\ \hline
B & 6.5 & 0   & 4.7 & 4.5 & 2.8 \\ \hline
C & 2.4 & 4.7 & 0   & 2.4 & 4.1 \\ \hline
D & 4.2 & 4.5 & 2.4 & 0   & 1.7 \\ \hline
E & 5.9 & 2.8 & 4.1 & 1.7 & 0   \\ \hline
\end{tabular}
\end{center}
Point names are denoted by the Letters $A,B,C,D,E$.
\begin{enumerate}
\item Construct a Dendogram for hierarchical agglomerative clustering  using the {\bf complete-linkage} procedure.
\item Identify the cluatering assignment of the points if one decides to split the data into two clusters. 
\end{enumerate}
}}{

}\\

Ans: 






%\newpage 
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Consider a clustering problem of bi-variate data with the following distance matrix: \\
%\begin{center}
%\begin{tabular}{|l|l|l|l|l|l|}
%\hline
%  & A   & B   & C   & D   & E   \\ \hline
%A & 0   & 4.9 & 5.6 & 1.3 & 4.2 \\ \hline
%B & 4.9 & 0   & 5.9 & 3.6 & 4.5 \\ \hline
%C & 5.6 & 5.9 & 0   & 5.3 & 2.6 \\ \hline
%D & 1.3 & 3.6 & 5.3 & 0   & 3.9 \\ \hline
%E & 4.2 & 4.5 & 2.6 & 3.9 & 0   \\ \hline
%\end{tabular}
%\end{center}
%Point names are denoted by the Letters $A,B,C,D,E$.
%\begin{enumerate}
%\item Construct a Dendogram for hierarchical agglomerative clustering  using the {\bf single-linkage} procedure.
%\item Identify the clustering assignment of the points if one decides to split the data into two clusters. 
%\end{enumerate}
%}}{
%
%}\\

\newpage 
\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider a clustering problem of bi-variate data
$$A=\ColVec{4,3},
B=\ColVec{2,2},
C=\ColVec{2,6},
D=\ColVec{5,0},
E=\ColVec{0,3},
F=\ColVec{4,0}, $$
where the points are labeled as A, B, C, D, E, F. The Euclidean distance between the points are provided in the distance matrix below:
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
  & A    & B    & C    & D    & E    & F    \\ \hline
A & 0    & 2.24 & 3.61 & 3.16 & 4    & 3    \\ \hline
B & 2.24 & 0    & 4    & 3.61 & 2.24 & 2.83 \\ \hline
C & 3.61 & 4    & 0    & 6.71 & 3.61 & 6.32 \\ \hline
D & 3.16 & 3.61 & 6.71 & 0    & 5.83 & 1    \\ \hline
E & 4    & 2.24 & 3.61 & 5.83 & 0    & 5    \\ \hline
F & 3    & 2.83 & 6.32 & 1    & 5    & 0    \\ \hline
\end{tabular}
\end{center}
\vspace{.2in}
 During an iteration of the K-means algorithm with 2 clusters, the points $\{A,D,F\}$ are assigned to Cluster1 and the rest of the points to the Cluster2. 
\begin{enumerate}
\item  Identify the resulting cluster centers for both the groups at the beginning   of the next iteration.
\item Compute the Withing Group Sum of Squares for  clusters provided in part(a).  Note that,  you may take help from the provided distance matrix. 
\end{enumerate}
}}{

}\\



%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Provide Spectral Decomposition and Ask Questions on Principal components
%\begin{enumerate}
%\item Question 1
%\item Question2
%\end{enumerate}
%}}{
%
%}\\
%








\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider a dataset that includes data on 150 diamonds sold at an auction.  We applied a regression-tree  model to  build a  model to  predict the price of a diamond  based on the 'weight',  `clarity', and `color' of a diamond.  
The variables that are present in the data are the following: \\
{\bf "value":} The price at which the diamond is sold.  (in $10^5$ USD)\\
{\bf "weight"}: Weight of the diamond.  (grams)\\
{\bf  "clarity"}: Clarity measure of the diamond.(A score between 0 to 2)\\
   {\bf "color" }: Color of the diamond. (A score between 1 to 10)\\
       

The following is the diagram of the obtained tree that we denote here by $\text{T}^{*}$ when modeling the continuous variable 'value':\\
\includegraphics[scale=.55]{TreeDiamond.png}
The numbers provided at the terminal node,  denote the the corresponding predicted response ans the number of observations are allocated to the specific terminal node.  Answer the following questions based on the estimated tree given in this problem. 
\begin{enumerate}
\item Let $ \alpha(\text{T})$ denote the usual complexity measure obtained by the number of the terminal node of the tree or the number of decision regions that it corresponds.  What is the value of $\alpha(\text{T}^{*})$?
\item Write down/Describe the  different decision regions that the tree corresponds to. 

\item What would be predicted response of a point that has the following values for the corresponding covariates\\
{\small
 \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|l|}
\hline
crim & zn   & indus & chas & nox  & rm   & age  & dis & rad & tax & ptratio & lstat & medv \\ \hline
0.17 & 12.5 & 7.87  & 0    & 0.53 & 6.01 & 85.9 & 6.5 & 5   & 311 & 15.2    & 17.1  &  ?    \\ \hline
\end{tabular}
}
\end{enumerate}
}}{

}\\





%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Provide R output of clustering and Ask Questions
%\begin{enumerate}
%\item 
%\item 
%
%\item
%\end{enumerate}
%}}{
%
%}\\
%
%
%
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Tree Complexity question  and pruning tree
%\begin{enumerate}
%\item 
%\item 
%
%\item
%\end{enumerate}
%}}{
%
%}\\
%
%
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%
%\begin{enumerate}
%\item 
%\item 
%
%\item
%\end{enumerate}
%}}{
%
%}\\
%
%
%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%
%\begin{enumerate}
%\item 
%\item 
%
%\item
%\end{enumerate}
%}}{
%
%}\\

%
%
%\item \QuizQ{ \TextInBoxOne{5.4in}{
%Question random forest
%\begin{enumerate}
%\item 
%\item 
%
%\item
%\end{enumerate}
%}}{
%
%}\\



\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider a small data set of 6 observations: \\
\begin{tabular}{|l|l|l|l|l|l|}
\hline
DataId & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species    \\ \hline
1      & 6.5          & 3           & 5.2          & 2           & virginica  \\ \hline
2      & 5.1          & 3.5         & 1.4          & 0.2         & setosa     \\ \hline
3      & 7            & 3.2         & 4.7          & 1.4         & versicolor \\ \hline
4      & 4.9          & 3           & 1.4          & 0.2         & setosa     \\ \hline
5      & 5.8          & 2.7         & 5.1          & 1.9         & virginica  \\ \hline
6      & 4.6          & 3.4         & 1.4          & 0.3         & setosa     \\ \hline
\end{tabular}
The objective of this problem is to obtain a bootstrap sample of the above data.  As we have only 6 observations here, we may assume that a random data row can be selected by rolling a dice.  In particular,  we can select the specific DataId that matches with the number that appears as a result of the throw of the dice.  The following is the results of 10 independent throws of a dice: 
$$\{ 5,  3,  4,  1 , 2,  4,  5,  1, 6 , 1\}$$


\begin{enumerate}
\item Obtain a Bootstrap sample of the above data. Clearly indicate which DataId's are you selecting.  
\end{enumerate}
}}{

}\\




\item \QuizQ{ \TextInBoxOne{5.4in}{
Let $\hat{\Sigma}$ be an estimated variance covariance matrix from a data set.  As the variance covariance matrix is non negative definite matrix, a spectral decomposition of the matrix is possible to be done.  Based on a computation procedure to applied to  $\hat{\Sigma}$, the following spectral decomposition is obtained:
$$\hat{\Sigma}:=\Gamma \Lambda \Gamma^T, \text{ where }$$

$$\Gamma=\RowVec{ \Col{0.78,0.24,0.37,0.06,-0.32,0.3,-0.06,-0.01} , \Col{-0.06,-0.33,0.66,0.22,0.21,-0.15,0.37,-0.46} , \Col{-0.04,0.78,-0.14,0.35,0.19,-0.21,0.05,-0.4} , \Col{-0.38,0.03,0.04,0.57,-0.61,0.21,0.25,0.21} , \Col{-0.26,0.27,0.45,-0.42,-0.42,-0.52,-0.19,0.1} , \Col{-0.13,0.25,0.41,0.17,0.52,0.14,-0.08,0.65} , \Col{-0.32,-0.03,0.18,0.05,0,0.46,-0.72,-0.37} , \Col{0.25,-0.29,-0.06,0.54,-0.01,-0.55,-0.49,0.13} }$$
$$\Lambda=\RowVec{ \Col{20,0,0,0,0,0,0,0} , \Col{0,15,0,0,0,0,0,0} , \Col{0,0,1.1,0,0,0,0,0} , \Col{0,0,0,0.9,0,0,0,0} , \Col{0,0,0,0,0.8,0,0,0} , \Col{0,0,0,0,0,0.5,0,0} , \Col{0,0,0,0,0,0,0.02,0} , \Col{0,0,0,0,0,0,0,0.001} }.$$
Note that $\Gamma$ is an Orthogonal-Matrix i.e. $\Gamma^T\Gamma=\Gamma\Gamma^T=\text{I}_{_{8\times 8}}$ while,  $\Lambda$ is a diagonal matrix with non-negative diagonal elements.  Also, note that the columns of the matrix $\Gamma$ comprises of the eigen-vectors of the matrix $\hat{\Sigma}$ while the diagonal elements of the matrix $\Lambda$ refers to the corresponding eigen-values of $\hat{\Sigma}$. Answer the following questions based on the results provided above.

\begin{enumerate}
\item   Derive the equation for the first three principal components of the observed data.  i.e.  What is the equation for the first three principal components, $\text{PC}_1$, $\text{PC}_2$, and $\text{PC}_3$, of the observed data? 
\item What is the loading of $\text{PC}_{1}$ on the different variables?
\item Derive the variance of $\text{PC}_{1}$.
\item Derive the co-variance between  $\text{PC}_{1}$ and $\text{PC}_{2}$.

\item Draw a scree plot of the importance factors for the principal components.  Based on the scree-plot,  identify the optimum number of components (say $m$) that would be adequate to capture the variability present in the observed data.  

\item  What is the  percentage of total variability that is captured by the first $m$ principal components of the data.  
\item If a specific observed data point is 
$X_ 1 = 2.44,X_ 2 = 4.82,X_ 3 = 2.43,X_ 4 = -0.2,X_ 5 = -0.29,X_ 6 = -3.32,X_ 7 = 1.77,X_ 8 = -7.65$
What is the score of the plot along the first two principal components?
\end{enumerate}
}}{

}\\





\item \QuizQ{ \TextInBoxOne{5.4in}{
Let $\hat{\Sigma}$ be an estimated variance covariance matrix from a data set.  As the variance covariance matrix is non negative definite matrix, a spectral decomposition of the matrix is possible to be done.  Based on a computation procedure to applied to  $\hat{\Sigma}$, the following spectral decomposition is obtained:
$$\hat{\Sigma}:=\Gamma \Lambda \Gamma^T, \text{ where }$$

$$\Gamma=\RowVec{ \Col{0.15,0.58,-0.06,-0.05,0.8} , \Col{0.93,0.03,0.28,0.14,-0.17} , \Col{0.11,0.22,-0.8,0.51,-0.22} , \Col{0.28,-0.21,-0.52,-0.78,0.01} , \Col{0.11,-0.76,-0.13,0.33,0.53} }$$
$$\Lambda=\RowVec{ \Col{12,0,0,0,0} , \Col{0,6,0,0,0} , \Col{0,0,1,0,0} , \Col{0,0,0,0.9,0} , \Col{0,0,0,0,0.1} }.$$
Note that $\Gamma$ is an Orthogonal-Matrix i.e. $\Gamma^T\Gamma=\Gamma\Gamma^T=\text{I}_{_{5\times 5}}$ while,  $\Lambda$ is a diagonal matrix with non-negative diagonal elements.  Also, note that the columns of the matrix $\Gamma$ comprises of the eigen-vectors of the matrix $\hat{\Sigma}$ while the diagonal elements of the matrix $\Lambda$ refers to the corresponding eigen-values of $\hat{\Sigma}$. Answer the following questions based on the results provided above.

\begin{enumerate}
\item   Derive the equation for the first three principal components of the observed data.  i.e.  What is the equation for the first three principal components, $\text{PC}_1$, $\text{PC}_2$, and $\text{PC}_3$, of the observed data? 
\item What is the loading of $\text{PC}_{1}$ on the different variables?
\item Derive the variance of $\text{PC}_{1}$.
\item Derive the co-variance between  $\text{PC}_{1}$ and $\text{PC}_{2}$.

\item Draw a scree plot of the importance factors for the principal components.  Based on the scree-plot,  identify the optimum number of components (say $m$) that would be adequate to capture the variability present in the observed data.  

\item  What is the  percentage of total variability that is captured by the first $m$ principal components of the data.  
\item If a specific observed data point is 
$X_ 1 = 2.44,X_ 2 = 4.82,X_ 3 = 2.43,X_ 4 = -0.2,X_ 5 = -0.29$
What is the score of the plot along the first two principal components?
\end{enumerate}
}}{

}\\




\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider the following diagram of a Perceptron:\\
\begin{center}
\includegraphics[scale=.38]{Perceptron_img.jpg}
\end{center}
Let the weights are given to be $\w_0=5$, $\w_1=2$, $\w_2=-3$, $\w_3=1$.  The observed covariates/imputs are given as
$x_1=4, x_2=1, X_3=-1$.  
\begin{enumerate}
\item Write down the mathemetical formulation of the above Perceptron.  Keep the nonlinear function to be the generic $f$ in your expression.
\item If we consider the nonlinear function $f$ to be the Sigmoid function, then what would be the output from the above Perceptron?
\item If we consider the nonlinear function $f$ to be the ReLU function, then what would be the output from the above Perceptron?
\end{enumerate}
}}{

}\\


\vspace{1.5in}
\item \QuizQ{ \TextInBoxOne{5.4in}{
Consider the dendrogram: \\
\begin{center}
\includegraphics[scale=.39]{dendo_2.jpg}
\end{center}
Using this dendrogram to create 4 clusters, what would the clusters be?
}}{
\begin{enumerate}
\item Identify the clusters if it is given that there is only three clusters. 
\item Identity the two points which are closest to each other. 
\end{enumerate}
}\\


\end{enumerate}






\end{document}